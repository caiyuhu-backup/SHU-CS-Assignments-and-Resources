# 系统结构

## 题型

选择题 10

判断 15

简答 25 共7道

上面都是送的 全都是书上的概念

应用 10 3道小计算

1. 流水线
2. 互联网络函数 
3. 交叉开关

编程 15 一道大题 OpenMP

MPI基本函数要知道

综合题 25 共3道 考验研讨的东西？ 书上东西的拓展

从存储角度如何提高速度？从流水线角度如何提高速度？GPU如何提高并行性？

### OpenMP和MPI

OpenMP 线程级别 多核共享存储

MPI 进程之间消息传递 多CPU之间

### MPI

cumm_size函数什么意思 启动、获取进程数、获取进程号

MPI 多CPU的进程之间的消息传递

### OpenMP

听起来像是从0开始写

编译指导语句 **for** 私有变量？公有变量？ fork-join过程要知道 critical 还是reduction 规约？ 看一看PI **头文件也要写** inlcude后面的不能少 

编译命令、运行命令都要有 再来一点性能的实验分析 对于负载的一些讨论 

局部性在哪里 开销在哪里

文件打开、文件读取 二进制文件的打开函数也要会写 CPP本身的功底 

## 第一章 计算机系统结构导论

1. 计算机系统结构的定义 p8 ==方+雪==
	- 计算机系统结构是指对机器语言计算机的软、硬件功能分配和界面的定义。
	- Amdahl：**程序员**（程序设计者）所看到的计算机属性，即**概念性结构**和**功能特性**，这实际上是计算机系统的**外特性**。

2. 计算机系统结构的组成和实现的区别，以及他们的关系 p9 p10 ==方+雪== **可能考简答**
	- 计算机系统结构是**计算机系统**的**概念性结构**和**功能特性**。
	- 计算机组成是**计算机系统结构**的**逻辑实现**。
	- 计算机实现是**计算机组成**的**物理实现**。
	- 总而言之，系统结构、组成和实现之间的关系应符合下列原则：系统结构设计不要对组成、实现有过多和不合理限制；组成世纪应在系统结构指导下，以目前能实现的技术为基础；实现应该在组成的逻辑结构下，以目前器件技术为基础，以优化性能价格比为目标。

3. 模拟和仿真的概念 p11 ==方+雪==

	- 肯定是不兼容的才需要模拟和仿真。 **可能考判断**
	- 用**机器语言程序**解释实现程序的移植方法称为模拟。
	- 用**微程序**直接解释另一种机器的指令系统称为仿真。
	- 仿真与模拟的主要区别在于解释用的语言。仿真使用**微程序**解释，器解释程序在微程序存储器；模拟是用**机器语言**程序解释，器解释程序在主存储器。

	<img src="https://shu-silence.oss-cn-shanghai.aliyuncs.com/img/2023/image-20230530134505514.png" alt="image-20230530134505514" style="zoom: 33%;" />

4. 软件和硬件的关系 p12 + p14

	- 用软件实现优点是设计容易，修改方便；用硬件实现优点是速度快，有较好性能。但并非硬件实现一定比软件实现速度快，算法在其中起重要作用。
	- 因此，进行软、硬件功能分配时，应在现有硬件和芯片条件下，争取使系统有较高的性能价格比

	简答题：简要概括计算机系统的组成

	- 计算机系统由硬件和软件组成，二者是不可分割的整体。

	- 硬件是计算机系统中的实际装置，是系统的基础和核心，一般由CPU、MEM、I/O接口、BUS和外部设备等组成，它以机器语言（即指令系统）提供给程序员使用。软件指操作系统、汇编程序、编译程序、文本编辑程序、调试程序、数据库管理系统、文字处理系统、诊断程序以及各种应用程序等，基本上已与硬件的实现无关。

	简答题：简述计算机系统结构、组成和实现这三折的内容以及关系。

	- 系统结构是计算机系统的软、硬件界面，计算机组成是计算机系统结构的逻辑实现，计算机实现是计算机组成的物理实现。它们各自有不同的内容，但又有紧密的关系。系统结构设计不要对组成、实现有过多和不合理限制；组成设计应在系统结构指导下，以目前能实现的技术为基础；实现应在组成的逻辑结构指导下，以目前器件技术为基础，以优化性能价格比为目标。

5. 从中间开始的设计方法 p15

判断题：计算机设计的方法从中间开始是比较合适的，从层次结构的软银见的洁面开始，合理的进行软件功能分配，合理的进行软件监控。✅

由上向下or由下而上均使软，硬件设计脱节。正确方法是，中间开始，即软/硬件界面。 往往先硬后软，软硬统筹。 (CX PPT的原画)✅

6. Flynn分类法 p16 ==方+雪==

简答题：举出Flynn发的四种计算机系统结构，每种举出一个例子。

- SISD
	- 串行处理机

- SIMD
	- CUDA 阵列处理机 并行处理机 MMX AVX SVE

- MISD
- MIMD
	- 多处理机 多计算机

7. 透明性定义 p8

- 所谓“透明性”，一是指确实存在，二是指无法检测和设置。
- 在计算机系统中，低层的概念性结构和功能特性对高层来说是透明的。

8. 兼容性 p11 ==方+雪==

- 系列机**系统软件**必须兼容，系列机软件兼容指同一个软件（目标程序）可以不加修改地运行于系统结构相同的各机器上，并且所得结果一致。

- 向上兼容：抵挡机器的目标程序不加修改可以运行与高档程序。 向前（后）兼容：系列机投放市场先后实现软件兼容。
- 一般采用，**向上兼容，向后兼容**。 一定是向后哈 **可能考判断，并且给出向前兼容的选项，这个时候选 ❌**

9. 计算机是软件、硬件组成的 ❌ **为什么？？**
10. SIMT与SFMD的区别和联系 p18 **可能考简答题** ==方+雪==

- cx说GPU是SIMT lff说GPU是SIMD
- SIMT线程级别并行
- SIMD数据之间的并行
- 在SIMD上有很多处理单元做向量计算，想让他提高效率，加速，只能增加硬件或者处理机。
- **在SIMT上想提高效率，提高并行度，可以增加什么呢？**
	- 避免分枝

- SIMT和SIMD之间有些许不同

![image-20230526235859988](https://shu-silence.oss-cn-shanghai.aliyuncs.com/img/2023/image-20230526235859988.png)

![image-20230526235849690](https://shu-silence.oss-cn-shanghai.aliyuncs.com/img/2023/image-20230526235849690.png)

![image-20230526235830315](https://shu-silence.oss-cn-shanghai.aliyuncs.com/img/2023/image-20230526235830315.png)

11. 虚拟计算机的层次结构 p11
11. 系列机是指：**具有相同的系统结构，但组成和实现技术不同的一系列计算机系统**

## 第二章 处理器及其相关技术

1. 缩短地址码的方法 -> 哈夫曼编码 p27 **可能考填空**
2. 指令系统的设计要求 **可能考填空** ==方+雪==

规整性、高效性、兼容性 3个

3. CUDA编程基于**SIMD**编程模型，在GPU上执行的代码被称为**核函数** p48 ==方+雪==

	但是GPU是基于**SIMT**的 p18

4. GPU相关概念 p47 **可能考简答**

GPU是**SIMT**类型的系统结构，在GPU中基本的运算单元被称为**流处理器**。多个流处理器、缓存和指令控制单元组成**流多处理器**。SM是GPU执行指令的基本单位，在同一流多处理器内的流处理器具有**共享**的高速一级**缓存**。整个GPU则有多组流多处理器、共享二级缓存和显存控制器等组成。

5. 二八定律 p29 **可能考判断，并且答案为 ✅**

一个典型程序的运算过程所使用的80%指令只占处理器指令系统所有指令中的20%，事实上最频繁使用的指令是取数据、存数据和加法等最简单的指令。

6. 时钟频率 p31 **可能考判断，并且答案为 ❌**

CPU的时钟频率是衡量CPU性能的核心指标之一，并且决定了CPU的性能 ❌

![image-20230527100647809](https://shu-silence.oss-cn-shanghai.aliyuncs.com/img/2023/image-20230527100647809.png)

7. GPU一定比CPU快 ❌
7. 进程是资源分配的最小单位，线程是CPU调度的最小单位。✅
7. 进程和线程的区别

<img src="https://shu-silence.oss-cn-shanghai.aliyuncs.com/img/2023/image-20230530154510828.png" alt="image-20230530154510828" style="zoom:50%;" />

10. 并行有三种实现方式：**指令级并行**、**线程级并行**、**数据并行** p57
11. 数据表示指能由**硬件**直接辨认的数据类型
12. 简答题：CPU的并行运算实现方式有哪几种？各有什么特点？（**要考SIMD和SIMT的区别**）

CPU并行运算有三种实现方式：指令级并行、线程级并行以及数据并行。各自特点如下：

1. 指令级并行是一种指令层面的并行技术，目的是使CPU能够在同一时刻并行执行多条指令，其基本原理是：当指令之间不相关时，它们可以重叠起来并行执行。

2. **线程级并行**是多处理器支持多个线程同时并行执行。实现CPU的线程级并行的基础是CPU具有多个物理内核，能够在每个内核上执行一个独立线程。

3. **数据并行**是指把需要处理的数据划分成若干个部分分配到不同的处理部件上，并在每个处理部件上运行相同的处理程序对所分派的数据进行处理，即遵循SIMD（单指令多数据流）模型。

13. 简述CUDA程序的一般执行流程
	1. 调用cudaMalloc()函数，在显存中开辟空间用于存储需要由GPU计算的数据。
	2. 调用cudaMemcpy()函数，将数据由主机内存复制到GPU显存中。
	3. 启动核函数，进行相关高并行度计算。
	4. 调用cudaMemcpy()函数，将数据由显存取回内存中。
	5. 调用cudaFree()函数，释放显存占用空间。

## 第三章 存储系统结构

1. 给你不同的存储介质，让你分析怎样去组织可以获得更好的性能。 **可能考简答**

物理材质本身

cache想要性能提升，需要怎么做？虚拟存储器想要性能变强的话，需要怎么做？

2. cache是在特殊位置使用的？ ❌ **可能考判断** ==方+雪==

cache以前只有单一的cache，现在可以做1级、2级、3级等多级，有的是做在CPU内，有的做在板上？不一定只是在特殊位置来使用的。 （没懂啥意思，这是lff原话）

3. 置换算法的堆栈 p72-p74 **可能考简答** ==方+雪==

对于置换算法进行分类，具有堆栈型特点的置换算法，我们认为是好的。FIFO、LRU、OPT中，哪些是堆栈型？原因是什么？

<img src="https://shu-silence.oss-cn-shanghai.aliyuncs.com/img/2023/image-20230530235513056.png" alt="image-20230530235513056" style="zoom: 33%;" />

<img src="https://shu-silence.oss-cn-shanghai.aliyuncs.com/img/2023/image-20230530235603841.png" alt="image-20230530235603841" style="zoom: 33%;" />

- FIFO 每次替换以先进入者为对象，**不是堆栈型算法**，实存页数增加，有时反而降低命中率，整体分析命中率较低。

- LRU 每次替换以之前未命中最多者为对象，**是堆栈型算法**，实存页数增加，命中率上升，整体分析命中率较高，实用性较强。
- OPT 每次替换以后最少使用这为对象，**是堆栈型算法**，实存页数增加，命中率上升，**整体分析命中率最高**，但使用困难，用于理论分析。

4. cache透明性（一致性） p87 **一定考简答** ==方+雪==

cache不一致的原因是什么？写回法和写直达法。是什么？各自的优缺点？针对单处理器的cache，不讨论多处理器。**写回法中，CPU中的数据只写入cache，不写入主存。**cx说这句话很重要。

原因：虽然Cache内存储的信息是贮存内存储的信息的副本，但是在一段时间内，主存内某单元的内容和Cache内对应单元的内容却可能是不同的。这些在通信过程中引起的**Cache内容跟不上主存对应内容**的变化， 或者**主存内容跟不上Cache内容**的变化的情况，在Cache对处理器和主存均是透明的前提下，可能引发错误。

两种方法：**写回法**、**写直达法**

- 写回法：（标志交换方式）只向Cache写入，并用标志注明，直至该块在替换中被排挤出来，才将该块写回主存，代替未经修改的原本。
- 写直达法：（通过式写、通过式存）在写入Cache的同时也写入主存，使原本和副本同时修改。

两者的区别：写回法仅仅在被替换时才将修改过的Cache块写回主存，后者在修改Cache的同时直接写入主存。写回法是把开销开销花在替换时，而写直达法在每次写Cache时都要附加一个写主存的开销，而写主存所花费的时间比写Cache长的多。

两者优缺点：

- 写回法：写操作速度较快，但在该块写回主存之前，主存中的原本由于未及时修改而失去时效。
- 写直达法：实现简单，能随时保持原本的时效，对于多处理器共享一个原本特别重要。可靠性更好。

5. 存储系统的层次结构？为什么存储结构可以提高速度？**可能考简答**

<img src="https://shu-silence.oss-cn-shanghai.aliyuncs.com/img/2023/image-20230527105622743.png" alt="image-20230527105622743" style="zoom:50%;" />

<img src="https://shu-silence.oss-cn-shanghai.aliyuncs.com/img/2023/image-20230531120844695.png" alt="image-20230531120844695" style="zoom: 33%;" />

- 提高cache命中率？如何提高命中率？**预取**，把内存的一大堆东西一个块，提前取到。程序和数据都有局部性原理。为啥存储系统比单个的存储器强？
- 并行。平铺提高速度的方法，低位交叉。流水线方式？**低位交叉存储体是采用流水线方式工作的并行存储系统。** 只有低位可以提高速度，高位交叉只能提高容量
- 虚拟存储器 Cache
- 程序访问的局部性原理  根据这个构建 速度价格容量 的指标

## 第四章 流水线结构

1. 什么是先行控制结构？ p120 p122 **可能考简答 **==方+雪==

把处理机中原来一个集中的控制器，分解为**存储控制器（存控）**、**指令控制器（指控）**、**运算控制器（运控）**三个部分。

先行控制技术实际上是**缓冲技术**和**预处理技术**相结合的产物。

图4-9

2. 流水线原理 p123 4.1.3 **可能考简答**

定义：流水线技术将一个重复的时序过程分解为若干个子过程，每个子过程都可以有效地在其专用功能上与其他子过程同时执行。

流水线的特点，或者说是实现流水线的方式。

特点：

- 可以划分为若干互相有联系的子过程（功能段），每个功能段由专用的功能部件实现。
- 每个子过程实现所需的时间应该尽可能相等，避免由于时间不等产生**处理瓶颈**，造成**流水线断流**
- 形成流水线处理，需要一段准备时间，称为“通过时间”。只有在此后流水过程才可以稳定
- 指令流不能顺序执行时，会造成流水线断流，再形成流水过程，需要一段准备时间。不应当经常断流，流水线效率会下降。
- 流水线技术适用于大量重复的程序过程，只有输入端能连续的提供服务，流水线效率才能够得到充分发挥。

3. 加速比的计算 p127 ==方+雪==
4. 非线性流水线的调度 预约表等 p130 **计算题** ==方+雪==
5. 超级流水处理机性能比较 p140 表 4-1 **可能考填空** ==方+雪==
6. 超级流水处理机的评价指标 p143
7.  ==方+雪==

记住式子 S(m,1) S(1,n) S(m,n) 

7. 数据相关 p148 第4题这一类 ==方+雪==

写写相关、写读相关、读写相关 不考调度

## 第五章 并行处理机与多处理机系统

1. 提高并行性的措施 p151 ==方+雪==

- **时间重叠、资源重复、资源共享**

- 普通流水线为时间重叠
- 超标量既有时间重叠，又有资源重复 空间换时间
- 超流水线 时间换空间
- 并行处理机（SIMD） 资源重复，并非时间重叠
- 同时性：超标量
- 并发性：单标量、超流水线

2. SIMD分两种，分布式存储器结构、共享式存储器结构。其中，采用分布式存储器的并行处理器是SIMD主流。
3. SIMD--主要有并行处理机、阵列处理机
4. 并行处理机是单机，不是多机！！！ ✅
5. ILLIAC 是阵列机 阵列处理机的代表 同时性！ 是SIMD 是资源重复，并非时间重叠 分布式存储器结构 p153 **可能考判断题** ==方+雪==
6. 并行处理机（SIMD计算机）的特点、原理 p151 p160 **可能考简答题** ==方+雪==

分为两种，一种是CPU、一种是GPU 两者对比？ ff圣经2，27分钟的时候说的

4. 混连函数 p163 **计算题** ==方+雪==

混洗、方体、PM2I的表达式子

5. 动态互联网络 p174 **计算题**

要不是多个cube 要不是多个shuffle 一定是 2功能的控制信号 看清楚标1交换还是标0交换

5. 并行性的概念 p150

  并行性：在同一时刻或统一时间间隔内完成两种或两种以上的性质相同或不同的工作，只要在时间上相互重叠，均存在并行性。

  同时性 和 并发性

  判断题： 普通的一条流水线，只有并发性，没有同时性。 ✅ 

6. 并行性的执行角度和处理数据的角度 p150 ==方+雪==

7. 互联网络特性 ==cx说不用看== p165

8. 多处理机的概念 p182

优缺点？

## 第六章 集群、网格和云计算

> 方方直接没有说这章的内容，🥹

1. 共享存储和分布式存储 **可能考判断**

集群的性能只由机器cpu决定。 ❌ 和通信网络有关，和上层的硬件调度有关。

2. 集群

<img src="https://shu-silence.oss-cn-shanghai.aliyuncs.com/img/2023/image-20230531154728647.png" alt="image-20230531154728647" style="zoom:50%;" />

<img src="https://shu-silence.oss-cn-shanghai.aliyuncs.com/img/2023/image-20230531155518499.png" alt="image-20230531155518499" style="zoom: 33%;" />

3. MPI

- P221 前六个函数的各种参数要搞清楚。

- MPI Message Passing Interface 消息传递接口 用于实现基于**多进程**的并行编程 实现的是**多进程之间的通信**

- 6个基本的MPI函数

	- `MPI_Init(int *argc, char** argv[])` 该函数应该是第一个被调用的MPI函数，作用是初始化并行环境。 MPI将通过argc和argv得到命令行参数，**也就是说main函数必须带参数，否则会出错**。
	- `MPI_Comm_size(MPI_Comm comm, int* size)` 该函数的作用是**获得**通信域comm中规定的group包含的进程的数量。
	- `MPI_Comm_rank(MPI_Comm comm, int* rank)` 该函数的作用是的到本进程在通信空间中的rank值，即在组中的逻辑编号。
	- `MPI_Finalize(void)`该函数的作用是退出MPI系统，释放占用的资源，所有进程正常退出时都应该调用它，表明并行代码的结束，结束除了主进程之外的其他进程
	- `MPI_Send(buf, count, datatype, dest, tag, comm)` 该函数的作用是将从buf开始的count个数据发送给进程编号为dest的进程。
	- `MPI_Recv(buf, count, datatype, source, tag, comm, status)` 函数的作用是将接收到的数据保存在buf中。

	```cpp
	#include <stdio.h>
	#include <mpi.h>
	
	int main(int argc, char* argv[]) {
	    int size, rank, rc;
	    int dest = 1, source = 0, tag = 99;
	    int buf[4], recv_buf[4];
	    MPI_Status status;
	
	    rc = MPI_Init(&argc, &argv);   // 初始化MPI环境
	
	    MPI_Comm_size(MPI_COMM_WORLD, &size);   // 获取进程数目
	    MPI_Comm_rank(MPI_COMM_WORLD, &rank);   // 获取当前进程编号
	
	    printf("Hello world from process %d of %d\n", rank, size);
	
	    if (rank == 0) {
	        buf[0] = 1;
	        buf[1] = 2;
	        buf[2] = 3;
	        buf[3] = 4;
	        MPI_Send(buf, 4, MPI_INT, dest, tag, MPI_COMM_WORLD);   // 发送消息
	        printf("Process %d sent message to process %d\n", rank, dest);
	    } else if (rank == 1) {
	        MPI_Recv(recv_buf, 4, MPI_INT, source, tag, MPI_COMM_WORLD, &status);   // 接收消息
	        printf("Process %d received message from process %d: %d, %d, %d, %d\n",
	                rank, source, recv_buf[0], recv_buf[1], recv_buf[2], recv_buf[3]);
	    }
	
	    MPI_Finalize();   // 结束MPI环境
	
	    return 0;
	}
	
	```

## 编程题

OPENMP

- 流文件或者二进制文件之中读取数据，读完之后要打开、关闭文件。

```cpp
	#include <iostream>
	#include <fstream>
	
	using namespace std;
	
	int main() {
	    string filename = "data.txt";
	  
	    ifstream fin;
			fin.open(filename); // 打开文件
	  
	    string line;
	    while (getline(fin, line)) {
	        cout << line << endl; // 输出到终端
	    }
	
	    fin.close(); // 关闭文件
	
	    ofstream fout;
	    fout.open("output.txt"); // 打开
	
	    fout << "This is added text." << endl; // 向文件中输出
	
	    fout.close(); // 关闭文件
	
	    return 0;
	}
```

```cpp
#include <iostream>
#include <fstream>
#include <vector>

int main()
{
    std::ifstream infile("input.txt");
    std::vector<int> nums;  // 用vector来存储读入的数字

    int num;
    while (infile >> num)  // 只要还能读入一个数字，就继续读取
    {
        nums.push_back(num);  // 将读入的数字存储到vector中
    }

    for (int i = 0; i < nums.size(); i++)
    {
        std::cout << nums[i] << " ";  // 输出vector中存储的数字
    }
    std::cout << std::endl;

    return 0;
}
```

- 会告诉当前的机器配置是什么，比如有几个核，有几个核就用几个核

- include哪些头文件？ 头文件好像共6个，共3分，错1个扣1分，扣完为止。

```cpp
#include<fstream>
#include<iostream>
#include<omp.h>
#include<time.h>

omp_get_therad_num(); // 返回线程号
omp_set_num_threads(); // 设置后续并行域中的线程个数
omp_get_num_threads(); // 返回当前并行域中的线程数
omp_get_num_procs(); // 返回系统中处理器的个数
```

```cpp
// 用reduction
#include <stdio.h>
#include <omp.h>

int main() {
    int a[] = {1, 2, 3, 4, 5};
    int n = sizeof(a) / sizeof(a[0]);
    int product = 1;

    omp_set_num_threads(16); // 设置线程数量为16
#pragma omp parallel for reduction(*:product)
    for (int i = 0; i < n; i++) {
        product *= a[i];
    }

    printf("the product is: %d\n", product);
    return 0;
}
```

```cpp
// 不用reduction
#include <stdio.h>
#include <omp.h>

int main() {
    int a[] = {1, 2, 3, 4, 5};
    int n = sizeof(a) / sizeof(a[0]);
    int product = 1;

    omp_set_num_threads(16); // 设置线程数量为16

#pragma omp parallel
{
    int local_product = 1;
#pragma omp for
    for (int i = 0; i < n; i++) {
        local_product *= a[i];
    }
#pragma omp critical
    {
        product *= local_product;
    }
}

    printf("the product is: %d\n", product);
    return 0;
}
```

- 写出编译命令和运行命令

```bash
g++ -fopenmp main.cpp -o main -lomp # 编译
./main # 运行
```

- 私有变量和公有变量
- **描述fork-join的过程？**

OpenmMP的执行模型采用Fork-Join的形式，将程序中执行时间长的循环部分通过**多线程**再多核上并行执行，提高计算速度。Fork-Join执行模式在开始执行的时候，只有一个“主线程”在运行。主线程在运行过程中，当遇到需要进行并行计算的时候，派生出线程来并行执行。在并行执行开始阶段（Fork阶段），主线程和派生线程被分配到空闲的CPU内核上并行执行，当线程执行完成后，就会退出并释放CPU内核（即Join阶段）。当所有线程都完成后，主线程将开始执行串行部分，这就是一个Fork-Join过程。

- 已经完全的利用算力的情况下，如何提高速度？

**负载均衡**。负载均衡对并行程序的性能至关重要，因为在并行运算中，有些线程可能会比其他线程运行的更快或者更慢，如果不将任务正确地分配给每个线程，会导致有些线程空闲，而其他线程处于过载状态，并且整个并行程序得不到最优的性能。

动态负载均衡。`#pragma omp parallel for schedule(dynamic, chunk_size)`，其中，chunk_size是每个线程从任务池中获取任务的块大小。将任务块放入任务池中，每个线程获取池中的一块任务并执行。执行完成后，线程将结果返回池中并继续获取下一个任务块。通过这种方式，任务块可以动态分配给空闲线程，以达到更好的负载均衡效果。

**扩展指令集**

- OpenMP的编程模型是**多线程并行**，采用**共享内存模型**。默认情况下，所有数据均是私有的，并行区域中的所有线程可以同时访问这些共享的数据，也可以置顶哪些数据是私有的。

## 问题

- cx的1h04min说的是什么题？

	<img src="https://shu-silence.oss-cn-shanghai.aliyuncs.com/img/2023/image-20230531150658308.png" alt="image-20230531150658308" style="zoom:50%;" />

- 预约表那张图的循环